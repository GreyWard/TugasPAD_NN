{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Acoustic Features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalisasi data dengan Z-score**\n",
    "$$ X(stand) = \\frac{x - mean (x)}{std_\\text{dev}} $$\n",
    "dimana $${mean = 0}, {std_\\text{dev}} = 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, i):\n",
    "    # Initialize a list to store the means of each column\n",
    "    means = [0] * i\n",
    "    # Initialize a list to store the standard deviations of each column\n",
    "    stds = [1] * i\n",
    "    # Loop through the columns\n",
    "    for j in range(i):\n",
    "        # Compute the mean of the column\n",
    "        mean = data.iloc[:, j].mean()\n",
    "        # Compute the standard deviation of the column\n",
    "        std = data.iloc[:, j].std()\n",
    "        # Store the mean and standard deviation\n",
    "        means[j] = mean\n",
    "        stds[j] = std\n",
    "    # Loop through the rows\n",
    "    for index, row in data.iterrows():\n",
    "        # Loop through the columns\n",
    "        for j in range(i):\n",
    "            # Normalize the value by subtracting the mean and dividing by the standard deviation\n",
    "            row[j] = (row[j] - means[j]) / stds[j]\n",
    "    # Return the normalized data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah data dinormalisasi, selanjutnya ialah PCA\n",
    "\n",
    "- menghitung covariance matrix\n",
    "\\begin{align}\n",
    "        Cov (\\sum) = \\begin{pmatrix}\n",
    "        cov (x_1,x_1) & cov(x_1,x_2) & ... & cov(x_1,x_m) \\\\\n",
    "        | & | & | & | \\\\\n",
    "        cov (x_m,x_1) & cov(x_m,x_2) & ... & cov(x_m,x_m)\n",
    "        \\end{pmatrix}\n",
    "    \\end{align}\n",
    "  di mana \\(X\\) adalah matriks data yang memiliki dimensi \\(n x m\\), dengan \\(n\\) adalah jumlah sampel dan \\(m\\) adalah jumlah fitur.\n",
    "- menghitung eigenvalue dan eigenvector\n",
    "$$ AX = Î»X $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split feature and target\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_RMSenergy_Mean</th>\n",
       "      <th>_Lowenergy_Mean</th>\n",
       "      <th>_Fluctuation_Mean</th>\n",
       "      <th>_Tempo_Mean</th>\n",
       "      <th>_MFCC_Mean_1</th>\n",
       "      <th>_MFCC_Mean_2</th>\n",
       "      <th>_MFCC_Mean_3</th>\n",
       "      <th>_MFCC_Mean_4</th>\n",
       "      <th>_MFCC_Mean_5</th>\n",
       "      <th>_MFCC_Mean_6</th>\n",
       "      <th>...</th>\n",
       "      <th>_Chromagram_Mean_9</th>\n",
       "      <th>_Chromagram_Mean_10</th>\n",
       "      <th>_Chromagram_Mean_11</th>\n",
       "      <th>_Chromagram_Mean_12</th>\n",
       "      <th>_HarmonicChangeDetectionFunction_Mean</th>\n",
       "      <th>_HarmonicChangeDetectionFunction_Std</th>\n",
       "      <th>_HarmonicChangeDetectionFunction_Slope</th>\n",
       "      <th>_HarmonicChangeDetectionFunction_PeriodFreq</th>\n",
       "      <th>_HarmonicChangeDetectionFunction_PeriodAmp</th>\n",
       "      <th>_HarmonicChangeDetectionFunction_PeriodEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.272863</td>\n",
       "      <td>0.724549</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.184485</td>\n",
       "      <td>1.940591</td>\n",
       "      <td>0.533531</td>\n",
       "      <td>1.342709</td>\n",
       "      <td>0.176184</td>\n",
       "      <td>0.194331</td>\n",
       "      <td>0.383737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207447</td>\n",
       "      <td>1.143513</td>\n",
       "      <td>-1.063516</td>\n",
       "      <td>-0.825846</td>\n",
       "      <td>-0.221041</td>\n",
       "      <td>1.447311</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>-0.794990</td>\n",
       "      <td>-2.447998</td>\n",
       "      <td>0.849226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141269</td>\n",
       "      <td>-2.270546</td>\n",
       "      <td>-0.198455</td>\n",
       "      <td>0.542841</td>\n",
       "      <td>2.017159</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>1.320472</td>\n",
       "      <td>1.910184</td>\n",
       "      <td>3.700735</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.057144</td>\n",
       "      <td>1.143513</td>\n",
       "      <td>-1.088927</td>\n",
       "      <td>1.695816</td>\n",
       "      <td>-0.779237</td>\n",
       "      <td>0.384200</td>\n",
       "      <td>-0.791482</td>\n",
       "      <td>1.701411</td>\n",
       "      <td>-0.935784</td>\n",
       "      <td>0.074540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.365871</td>\n",
       "      <td>1.670369</td>\n",
       "      <td>1.561337</td>\n",
       "      <td>1.891824</td>\n",
       "      <td>0.406721</td>\n",
       "      <td>1.535389</td>\n",
       "      <td>0.042915</td>\n",
       "      <td>1.076549</td>\n",
       "      <td>0.532379</td>\n",
       "      <td>0.490894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514324</td>\n",
       "      <td>0.435849</td>\n",
       "      <td>-1.038105</td>\n",
       "      <td>1.741509</td>\n",
       "      <td>1.525571</td>\n",
       "      <td>2.255275</td>\n",
       "      <td>1.278046</td>\n",
       "      <td>-0.101486</td>\n",
       "      <td>-1.074519</td>\n",
       "      <td>-0.958374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013743</td>\n",
       "      <td>0.961004</td>\n",
       "      <td>1.499939</td>\n",
       "      <td>-1.697403</td>\n",
       "      <td>0.489565</td>\n",
       "      <td>2.739475</td>\n",
       "      <td>0.414284</td>\n",
       "      <td>1.155465</td>\n",
       "      <td>-0.881279</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949773</td>\n",
       "      <td>1.143513</td>\n",
       "      <td>-0.577529</td>\n",
       "      <td>1.047552</td>\n",
       "      <td>1.687627</td>\n",
       "      <td>1.532360</td>\n",
       "      <td>0.396581</td>\n",
       "      <td>-1.524938</td>\n",
       "      <td>-0.366969</td>\n",
       "      <td>0.332769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.055845</td>\n",
       "      <td>0.724549</td>\n",
       "      <td>1.196106</td>\n",
       "      <td>-1.024616</td>\n",
       "      <td>0.961525</td>\n",
       "      <td>0.283066</td>\n",
       "      <td>1.096254</td>\n",
       "      <td>0.240752</td>\n",
       "      <td>1.285306</td>\n",
       "      <td>1.197156</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.051179</td>\n",
       "      <td>-0.516990</td>\n",
       "      <td>2.087458</td>\n",
       "      <td>-1.111424</td>\n",
       "      <td>0.301142</td>\n",
       "      <td>1.447311</td>\n",
       "      <td>0.846895</td>\n",
       "      <td>-1.102619</td>\n",
       "      <td>-1.324242</td>\n",
       "      <td>-2.507745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.618294</td>\n",
       "      <td>0.468390</td>\n",
       "      <td>-0.837272</td>\n",
       "      <td>1.098253</td>\n",
       "      <td>0.670316</td>\n",
       "      <td>-0.019347</td>\n",
       "      <td>0.772150</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>0.419696</td>\n",
       "      <td>0.315546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>0.692168</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>-0.757307</td>\n",
       "      <td>-0.094997</td>\n",
       "      <td>-1.125418</td>\n",
       "      <td>1.143910</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>1.353348</td>\n",
       "      <td>0.590997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.649296</td>\n",
       "      <td>-1.107976</td>\n",
       "      <td>-0.937947</td>\n",
       "      <td>1.645996</td>\n",
       "      <td>0.425549</td>\n",
       "      <td>-0.414524</td>\n",
       "      <td>-0.497260</td>\n",
       "      <td>-0.143068</td>\n",
       "      <td>-0.789084</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.003458</td>\n",
       "      <td>1.143513</td>\n",
       "      <td>0.943959</td>\n",
       "      <td>-1.085722</td>\n",
       "      <td>-1.715565</td>\n",
       "      <td>-1.401827</td>\n",
       "      <td>1.383439</td>\n",
       "      <td>1.701411</td>\n",
       "      <td>1.519830</td>\n",
       "      <td>0.074540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.819810</td>\n",
       "      <td>0.054594</td>\n",
       "      <td>-1.081512</td>\n",
       "      <td>0.301685</td>\n",
       "      <td>-0.977778</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>1.319076</td>\n",
       "      <td>-0.508954</td>\n",
       "      <td>0.312135</td>\n",
       "      <td>0.851331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.908018</td>\n",
       "      <td>-1.129927</td>\n",
       "      <td>-0.177304</td>\n",
       "      <td>-0.825846</td>\n",
       "      <td>-1.067338</td>\n",
       "      <td>-0.763960</td>\n",
       "      <td>1.057680</td>\n",
       "      <td>1.701411</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>-1.216602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.091250</td>\n",
       "      <td>0.369867</td>\n",
       "      <td>-1.196183</td>\n",
       "      <td>-0.298621</td>\n",
       "      <td>-0.569834</td>\n",
       "      <td>-0.529552</td>\n",
       "      <td>0.691124</td>\n",
       "      <td>0.215643</td>\n",
       "      <td>0.117501</td>\n",
       "      <td>0.110973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654503</td>\n",
       "      <td>1.143513</td>\n",
       "      <td>-0.123306</td>\n",
       "      <td>-0.714470</td>\n",
       "      <td>-0.923287</td>\n",
       "      <td>-1.040369</td>\n",
       "      <td>0.578622</td>\n",
       "      <td>1.701411</td>\n",
       "      <td>0.576431</td>\n",
       "      <td>0.590997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-0.745820</td>\n",
       "      <td>-1.561181</td>\n",
       "      <td>-0.802058</td>\n",
       "      <td>0.822192</td>\n",
       "      <td>-0.264818</td>\n",
       "      <td>-0.165915</td>\n",
       "      <td>1.163776</td>\n",
       "      <td>-0.178939</td>\n",
       "      <td>0.829452</td>\n",
       "      <td>1.104611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.767839</td>\n",
       "      <td>1.143513</td>\n",
       "      <td>-0.790347</td>\n",
       "      <td>-1.020039</td>\n",
       "      <td>-2.399805</td>\n",
       "      <td>-1.763285</td>\n",
       "      <td>0.061240</td>\n",
       "      <td>-1.217309</td>\n",
       "      <td>1.089751</td>\n",
       "      <td>-0.441917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows Ã 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     _RMSenergy_Mean  _Lowenergy_Mean  _Fluctuation_Mean  _Tempo_Mean  \\\n",
       "0          -1.272863         0.724549           0.910332     0.184485   \n",
       "1          -0.141269        -2.270546          -0.198455     0.542841   \n",
       "2          -1.365871         1.670369           1.561337     1.891824   \n",
       "3           0.013743         0.961004           1.499939    -1.697403   \n",
       "4          -1.055845         0.724549           1.196106    -1.024616   \n",
       "..               ...              ...                ...          ...   \n",
       "395         0.618294         0.468390          -0.837272     1.098253   \n",
       "396         0.649296        -1.107976          -0.937947     1.645996   \n",
       "397         0.819810         0.054594          -1.081512     0.301685   \n",
       "398         0.091250         0.369867          -1.196183    -0.298621   \n",
       "399        -0.745820        -1.561181          -0.802058     0.822192   \n",
       "\n",
       "     _MFCC_Mean_1  _MFCC_Mean_2  _MFCC_Mean_3  _MFCC_Mean_4  _MFCC_Mean_5  \\\n",
       "0        1.940591      0.533531      1.342709      0.176184      0.194331   \n",
       "1        2.017159      0.817391      0.998348      1.320472      1.910184   \n",
       "2        0.406721      1.535389      0.042915      1.076549      0.532379   \n",
       "3        0.489565      2.739475      0.414284      1.155465     -0.881279   \n",
       "4        0.961525      0.283066      1.096254      0.240752      1.285306   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "395      0.670316     -0.019347      0.772150      0.061397      0.419696   \n",
       "396      0.425549     -0.414524     -0.497260     -0.143068     -0.789084   \n",
       "397     -0.977778      0.910155      1.319076     -0.508954      0.312135   \n",
       "398     -0.569834     -0.529552      0.691124      0.215643      0.117501   \n",
       "399     -0.264818     -0.165915      1.163776     -0.178939      0.829452   \n",
       "\n",
       "     _MFCC_Mean_6  ...  _Chromagram_Mean_9  _Chromagram_Mean_10  \\\n",
       "0        0.383737  ...            0.207447             1.143513   \n",
       "1        3.700735  ...           -1.057144             1.143513   \n",
       "2        0.490894  ...           -0.514324             0.435849   \n",
       "3        0.505506  ...           -0.949773             1.143513   \n",
       "4        1.197156  ...           -1.051179            -0.516990   \n",
       "..            ...  ...                 ...                  ...   \n",
       "395      0.315546  ...            0.052356             0.692168   \n",
       "396     -0.001054  ...           -1.003458             1.143513   \n",
       "397      0.851331  ...           -0.908018            -1.129927   \n",
       "398      0.110973  ...           -0.654503             1.143513   \n",
       "399      1.104611  ...           -0.767839             1.143513   \n",
       "\n",
       "     _Chromagram_Mean_11  _Chromagram_Mean_12  \\\n",
       "0              -1.063516            -0.825846   \n",
       "1              -1.088927             1.695816   \n",
       "2              -1.038105             1.741509   \n",
       "3              -0.577529             1.047552   \n",
       "4               2.087458            -1.111424   \n",
       "..                   ...                  ...   \n",
       "395             0.222920            -0.757307   \n",
       "396             0.943959            -1.085722   \n",
       "397            -0.177304            -0.825846   \n",
       "398            -0.123306            -0.714470   \n",
       "399            -0.790347            -1.020039   \n",
       "\n",
       "     _HarmonicChangeDetectionFunction_Mean  \\\n",
       "0                                -0.221041   \n",
       "1                                -0.779237   \n",
       "2                                 1.525571   \n",
       "3                                 1.687627   \n",
       "4                                 0.301142   \n",
       "..                                     ...   \n",
       "395                              -0.094997   \n",
       "396                              -1.715565   \n",
       "397                              -1.067338   \n",
       "398                              -0.923287   \n",
       "399                              -2.399805   \n",
       "\n",
       "     _HarmonicChangeDetectionFunction_Std  \\\n",
       "0                                1.447311   \n",
       "1                                0.384200   \n",
       "2                                2.255275   \n",
       "3                                1.532360   \n",
       "4                                1.447311   \n",
       "..                                    ...   \n",
       "395                             -1.125418   \n",
       "396                             -1.401827   \n",
       "397                             -0.763960   \n",
       "398                             -1.040369   \n",
       "399                             -1.763285   \n",
       "\n",
       "     _HarmonicChangeDetectionFunction_Slope  \\\n",
       "0                                  0.166633   \n",
       "1                                 -0.791482   \n",
       "2                                  1.278046   \n",
       "3                                  0.396581   \n",
       "4                                  0.846895   \n",
       "..                                      ...   \n",
       "395                                1.143910   \n",
       "396                                1.383439   \n",
       "397                                1.057680   \n",
       "398                                0.578622   \n",
       "399                                0.061240   \n",
       "\n",
       "     _HarmonicChangeDetectionFunction_PeriodFreq  \\\n",
       "0                                      -0.794990   \n",
       "1                                       1.701411   \n",
       "2                                      -0.101486   \n",
       "3                                      -1.524938   \n",
       "4                                      -1.102619   \n",
       "..                                           ...   \n",
       "395                                     0.980038   \n",
       "396                                     1.701411   \n",
       "397                                     1.701411   \n",
       "398                                     1.701411   \n",
       "399                                    -1.217309   \n",
       "\n",
       "     _HarmonicChangeDetectionFunction_PeriodAmp  \\\n",
       "0                                     -2.447998   \n",
       "1                                     -0.935784   \n",
       "2                                     -1.074519   \n",
       "3                                     -0.366969   \n",
       "4                                     -1.324242   \n",
       "..                                          ...   \n",
       "395                                    1.353348   \n",
       "396                                    1.519830   \n",
       "397                                    0.687419   \n",
       "398                                    0.576431   \n",
       "399                                    1.089751   \n",
       "\n",
       "     _HarmonicChangeDetectionFunction_PeriodEntropy  \n",
       "0                                          0.849226  \n",
       "1                                          0.074540  \n",
       "2                                         -0.958374  \n",
       "3                                          0.332769  \n",
       "4                                         -2.507745  \n",
       "..                                              ...  \n",
       "395                                        0.590997  \n",
       "396                                        0.074540  \n",
       "397                                       -1.216602  \n",
       "398                                        0.590997  \n",
       "399                                       -0.441917  \n",
       "\n",
       "[388 rows x 50 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = normalize(X,50)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **One-hot Encoding for y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>happy</th>\n",
       "      <th>relax</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     angry  happy  relax    sad\n",
       "0    False  False   True  False\n",
       "1    False  False   True  False\n",
       "2    False  False   True  False\n",
       "3    False  False   True  False\n",
       "4    False  False   True  False\n",
       "..     ...    ...    ...    ...\n",
       "395   True  False  False  False\n",
       "396   True  False  False  False\n",
       "397   True  False  False  False\n",
       "398   True  False  False  False\n",
       "399   True  False  False  False\n",
       "\n",
       "[388 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y, columns = ['Class'])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fungsi Aktifasi:**\n",
    "\n",
    "- Sigmoid:\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}} $$\n",
    "$$\\sigma'(x) = \\sigma(x) \\cdot (1 - \\sigma(x))$$\n",
    "- Softmax:\n",
    "$${softmax}(x_i) = \\frac{e^{x_i - \\max(x)}}{\\sum{e^{x - \\max(x)}}} $$\n",
    "$$ softmax'(x) = $$\n",
    "- ReLU\n",
    "$${ReLU}(x) = \\max(0, x) $$\n",
    "$${ReLU}'(x) = \\begin{cases} 1 & \\text{jika } x > 0 \\\\ 0 & \\text{jika } x \\leq 0 \\end{cases} $$\n",
    "\n",
    "\n",
    "**Loss Function:**\n",
    "- Categorical Cross-Entropy:\n",
    "$${CCE}(y_{\\text{true}}, y_{\\text{pred}}) = -\\frac{1}{N} \\sum{y_{\\text{true}} \\cdot \\log(y_{\\text{pred}})} $$\n",
    "- Turunan Categorical Cross-Entropy:\n",
    "   $${CCE}'(y_{\\text{true}}, y_{\\text{pred}}) = -\\frac{y_{\\text{true}}}{y_{\\text{pred}}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Define the activation functions and their derivatives\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def softmax_derivative(x):\n",
    "    s = softmax(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# Define the loss functions and their derivatives\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    # Clip the predictions to avoid log(0) error\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    # Compute the cross entropy\n",
    "    return -np.mean(y_true * np.log(y_pred))\n",
    "\n",
    "def categorical_crossentropy_derivative(y_true, y_pred):\n",
    "    # Clip the predictions to avoid division by zero error\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    # Compute the derivative of cross entropy\n",
    "    return - (y_true / y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class for a layer of the neural network\n",
    "class FCLayer(Layer):\n",
    "    # Initialize the layer with the number of inputs, outputs, activation function, and weight initialization method\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size,output_size) - 0.5\n",
    "        self.bias = np.random.rand(1,output_size) - 0.5\n",
    "    # propagate prediction from given input\n",
    "    def forward(self,input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "    # backward propagation, computes dE/dW, dE/dB for given output_error=dE/dY. returns input_error=dE/dX\n",
    "    def backward(self,output_error,learning_rate):\n",
    "        input_error = np.dot(output_error,self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # update parameters\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit base class Layer\n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self,activation,activation_derivative):\n",
    "        self.activation = activation\n",
    "        self.activation_derivative = activation_derivative\n",
    "    # returns activated input\n",
    "    def forward(self,input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "    # returns input_error=dE/dX for given output_error-dE/dY\n",
    "    # learning_rate is not used because it is not learnable param\n",
    "    def backward(self,output_error,learning_rate):\n",
    "        return self.activation_derivative(self.input) * output_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class for the neural network\n",
    "class NeuralNetwork:\n",
    "    # Initialize the neural network with the number of features, the number of outputs, the loss function, and the optimizer\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_derivative = None\n",
    "    # add layer\n",
    "    def add(self,layer):\n",
    "        self.layers.append(layer)\n",
    "    #set loss\n",
    "    def use(self,loss,loss_derivative):\n",
    "        self.loss = loss\n",
    "        self.loss_derivative = loss_derivative\n",
    "    #predict output\n",
    "    def predict(self,input_data):\n",
    "        #sample dimension first\n",
    "        sample = len(input_data)\n",
    "        result = []\n",
    "        \n",
    "        #run network over samples\n",
    "        for i in range(samples):\n",
    "            #forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward(output)\n",
    "            result.append(output)\n",
    "        return result\n",
    "    #train network\n",
    "    def train(self, x_train, y_train, epochs, learning_rate):\n",
    "        #sample dimension first\n",
    "        samples = len(x_train)\n",
    "        #train loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward(output)\n",
    "                #compute loss\n",
    "                err += self.loss(y_train[j],output)\n",
    "                #backward prop\n",
    "                error = self.loss_derivative(y_train[j],output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward(error,learning_rate)\n",
    "            #calculate average error\n",
    "            err /= samples\n",
    "            print('epoch %d%d error = %f' % (i+1,epochs,err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (50,) and (1,32) not aligned: 50 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Michael\\Documents\\Kelas\\PAD\\Tugas\\Simplified.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m net\u001b[39m.\u001b[39muse(categorical_crossentropy, categorical_crossentropy_derivative)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m net\u001b[39m.\u001b[39;49mtrain(X\u001b[39m.\u001b[39;49mvalues, y\u001b[39m.\u001b[39;49mvalues, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# test\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m out \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mpredict(X\u001b[39m.\u001b[39mvalues)\n",
      "\u001b[1;32mc:\\Users\\Michael\\Documents\\Kelas\\PAD\\Tugas\\Simplified.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_derivative(y_train[j],output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         error \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackward(error,learning_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m#calculate average error\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m err \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m samples\n",
      "\u001b[1;32mc:\\Users\\Michael\\Documents\\Kelas\\PAD\\Tugas\\Simplified.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\u001b[39mself\u001b[39m,output_error,learning_rate):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     input_error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(output_error,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights\u001b[39m.\u001b[39mT)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     weights_error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput\u001b[39m.\u001b[39;49mT, output_error)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# update parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Michael/Documents/Kelas/PAD/Tugas/Simplified.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m weights_error\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (50,) and (1,32) not aligned: 50 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# network\n",
    "net = NeuralNetwork()\n",
    "net.add(FCLayer(50,32))\n",
    "net.add(ActivationLayer(relu,relu_derivative))\n",
    "net.add(FCLayer(32,4))\n",
    "net.add(ActivationLayer(softmax,softmax_derivative))\n",
    "\n",
    "# train\n",
    "net.use(categorical_crossentropy, categorical_crossentropy_derivative)\n",
    "net.train(X.values, y.values, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# test\n",
    "out = net.predict(X.values)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
